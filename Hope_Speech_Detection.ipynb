{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c2BAcKpIduqI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BkdCwbrSdwaH"
      },
      "outputs": [],
      "source": [
        "#reading datasets\n",
        "valid_data = pd.read_csv(\"Hope_ENG_dev.csv\")\n",
        "train_data = pd.read_csv(\"Hope_ENG_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fTx1X-YneDMs"
      },
      "outputs": [],
      "source": [
        "#adding column labels\n",
        "valid_data.columns =['text', 'label']\n",
        "train_data.columns =['text', 'label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HU8tTrTPXYG3",
        "outputId": "5276adf0-c4bc-4a77-bd5d-8a26c29cb2c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@Champions Again He got killed for using false...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's not that all lives don't matter</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it really that difficult to understand? Bla...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whenever we say black isn't that racists?  Why...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ros The Boss u don’t know that she’s actually ...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text            label\n",
              "0  @Champions Again He got killed for using false...  Non_hope_speech\n",
              "1               It's not that all lives don't matter  Non_hope_speech\n",
              "2  Is it really that difficult to understand? Bla...  Non_hope_speech\n",
              "3  Whenever we say black isn't that racists?  Why...  Non_hope_speech\n",
              "4  Ros The Boss u don’t know that she’s actually ...  Non_hope_speech"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_data.head()\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SJXcyzlXbHc",
        "outputId": "7e2900a2-7d18-423d-fb58-e809bc86a143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of training examples: 33680\n",
            "No. of testing examples: 8420\n"
          ]
        }
      ],
      "source": [
        "training_data = train_data.sample(frac=0.8, random_state=25)\n",
        "testing_data = train_data.drop(training_data.index)\n",
        "\n",
        "print(f\"No. of training examples: {training_data.shape[0]}\")\n",
        "print(f\"No. of testing examples: {testing_data.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPhbj9MxeEcj",
        "outputId": "99490a4b-cfb3-409e-fe34-228c5c90afda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                   text            label\n",
            "0     @Generation X Counting money that she been giv...  Non_hope_speech\n",
            "1     @Paola Hernandez i never said to be intolerant...  Non_hope_speech\n",
            "2     @Firstlast300 Wow An opinion is that I don't l...  Non_hope_speech\n",
            "3     WOW!!!!!!!That was so so inspiring and incredi...      Hope_speech\n",
            "4     @FALC0n  Yea sorry I know Asian is an ethnicit...  Non_hope_speech\n",
            "...                                                 ...              ...\n",
            "5011  i’m actually about to start my college on civi...      Hope_speech\n",
            "5012  @Sasha Dumse that is true. But we should ALL l...      Hope_speech\n",
            "5013                        Women need to keep fighting      Hope_speech\n",
            "5014  “God gave me a choice and my choice is love” t...      Hope_speech\n",
            "5015  why is there no footage of the riots and the v...      Hope_speech\n",
            "\n",
            "[5016 rows x 2 columns]\n",
            "                                                    text            label\n",
            "8480   I think you're awesome!  You tell it like it i...  Non_hope_speech\n",
            "1186                 Juan you are racist not these guys.  Non_hope_speech\n",
            "7818   I don't want Trump or Clinton as president eit...  Non_hope_speech\n",
            "24959  I am a female engineer and this made me cry. T...      Hope_speech\n",
            "16745  @*It's Maya* Nope... Just an American that's t...  Non_hope_speech\n",
            "...                                                  ...              ...\n",
            "37930  Madonna has been an advocate from day dot. She...      Hope_speech\n",
            "25966  Peace be upon you to our beloved brothers and ...      Hope_speech\n",
            "27917                           All lives matter to God.      Hope_speech\n",
            "36087  I loved the kids' reactions and comments.   I ...      Hope_speech\n",
            "34105  @Eric Taylor What school did you go to that ac...      Hope_speech\n",
            "\n",
            "[33680 rows x 2 columns]\n",
            "                                                    text            label\n",
            "20                        Clark thank you. I salute you.  Non_hope_speech\n",
            "22     Yall talking lesbian but I think it more likel...  Non_hope_speech\n",
            "28     The big ones stop ruling when the small ones s...  Non_hope_speech\n",
            "32     All I’m gunna say is I was Presbyterian and “d...  Non_hope_speech\n",
            "49     he was doing just fine before the police offic...  Non_hope_speech\n",
            "...                                                  ...              ...\n",
            "42078                                       She came out      Hope_speech\n",
            "42087  All lives matter even little.  EVEN LITTLE ABO...      Hope_speech\n",
            "42089  ALL LIVES MATTER! If you feel as if you deserv...      Hope_speech\n",
            "42094  All lives should matter. Not just only back li...      Hope_speech\n",
            "42098  I could maybe be sympathetic if they were less...      Hope_speech\n",
            "\n",
            "[8420 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "#printing our datasets\n",
        "print(valid_data)\n",
        "print(training_data)\n",
        "print(testing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "x9Oxe-K-eQ2W"
      },
      "outputs": [],
      "source": [
        "#encoding our data to 0 and 1\n",
        "training_data['enc_label'] = training_data['label'].replace({'Non_hope_speech':0, 'Hope_speech':1})\n",
        "valid_data['enc_label'] = valid_data['label'].replace({'Non_hope_speech':0, 'Hope_speech':1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3EeduYQeS3E",
        "outputId": "7135bac8-32d8-4be4-d5f5-55194e9e24e9"
      },
      "outputs": [],
      "source": [
        "#removing usernames\n",
        "import re\n",
        "\n",
        "def remove_usernames_links(tweet):\n",
        "    tweet = re.sub('@[^\\s]+','',tweet)\n",
        "    tweet = re.sub('http[^\\s]+','',tweet)\n",
        "    return tweet\n",
        "training_data['text'] = training_data['text'].apply(remove_usernames_links)\n",
        "\n",
        "#cleaning text\n",
        "\n",
        "import nltk\n",
        "import ssl\n",
        "\n",
        "'''try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context\n",
        "\n",
        "nltk.download()'''\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\") \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)  \n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "   \n",
        "\n",
        "training_data['cleanText']= training_data['text'].map(lambda s:preprocess(s)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "v0u_U6x9fwqt",
        "outputId": "b1eea256-4e44-4456-c4ea-540503ef09e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>enc_label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8480</th>\n",
              "      <td>I think you're awesome!  You tell it like it i...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "      <td>0</td>\n",
              "      <td>think awesome tell like matter color need join...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>Juan you are racist not these guys.</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "      <td>0</td>\n",
              "      <td>juan racist guys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7818</th>\n",
              "      <td>I don't want Trump or Clinton as president eit...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "      <td>0</td>\n",
              "      <td>want trump clinton president either nni hate w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24959</th>\n",
              "      <td>I am a female engineer and this made me cry. T...</td>\n",
              "      <td>Hope_speech</td>\n",
              "      <td>1</td>\n",
              "      <td>female engineer made cry woman awesome inspiri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16745</th>\n",
              "      <td>Maya* Nope... Just an American that's tired o...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "      <td>0</td>\n",
              "      <td>maya nope american tired ridicule mythical whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37930</th>\n",
              "      <td>Madonna has been an advocate from day dot. She...</td>\n",
              "      <td>Hope_speech</td>\n",
              "      <td>1</td>\n",
              "      <td>madonna advocate day dot fought hard lgbt peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25966</th>\n",
              "      <td>Peace be upon you to our beloved brothers and ...</td>\n",
              "      <td>Hope_speech</td>\n",
              "      <td>1</td>\n",
              "      <td>peace upon beloved brothers dearest sisters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27917</th>\n",
              "      <td>All lives matter to God.</td>\n",
              "      <td>Hope_speech</td>\n",
              "      <td>1</td>\n",
              "      <td>lives matter god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36087</th>\n",
              "      <td>I loved the kids' reactions and comments.   I ...</td>\n",
              "      <td>Hope_speech</td>\n",
              "      <td>1</td>\n",
              "      <td>loved kids reactions comments hope next genera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34105</th>\n",
              "      <td>Taylor What school did you go to that actuall...</td>\n",
              "      <td>Hope_speech</td>\n",
              "      <td>1</td>\n",
              "      <td>taylor school actually every school ever gives...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33680 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text            label  \\\n",
              "8480   I think you're awesome!  You tell it like it i...  Non_hope_speech   \n",
              "1186                 Juan you are racist not these guys.  Non_hope_speech   \n",
              "7818   I don't want Trump or Clinton as president eit...  Non_hope_speech   \n",
              "24959  I am a female engineer and this made me cry. T...      Hope_speech   \n",
              "16745   Maya* Nope... Just an American that's tired o...  Non_hope_speech   \n",
              "...                                                  ...              ...   \n",
              "37930  Madonna has been an advocate from day dot. She...      Hope_speech   \n",
              "25966  Peace be upon you to our beloved brothers and ...      Hope_speech   \n",
              "27917                           All lives matter to God.      Hope_speech   \n",
              "36087  I loved the kids' reactions and comments.   I ...      Hope_speech   \n",
              "34105   Taylor What school did you go to that actuall...      Hope_speech   \n",
              "\n",
              "       enc_label                                          cleanText  \n",
              "8480           0  think awesome tell like matter color need join...  \n",
              "1186           0                                   juan racist guys  \n",
              "7818           0  want trump clinton president either nni hate w...  \n",
              "24959          1  female engineer made cry woman awesome inspiri...  \n",
              "16745          0  maya nope american tired ridicule mythical whi...  \n",
              "...          ...                                                ...  \n",
              "37930          1  madonna advocate day dot fought hard lgbt peop...  \n",
              "25966          1        peace upon beloved brothers dearest sisters  \n",
              "27917          1                                   lives matter god  \n",
              "36087          1  loved kids reactions comments hope next genera...  \n",
              "34105          1  taylor school actually every school ever gives...  \n",
              "\n",
              "[33680 rows x 4 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zycBJbyWgm58",
        "outputId": "771a0e32-1301-4cfb-bda5-a76a213da727"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>enc_label</th>\n",
              "      <th>cleanText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8480</th>\n",
              "      <td>0</td>\n",
              "      <td>think awesome tell like matter color need join...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>0</td>\n",
              "      <td>juan racist guys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7818</th>\n",
              "      <td>0</td>\n",
              "      <td>want trump clinton president either nni hate w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24959</th>\n",
              "      <td>1</td>\n",
              "      <td>female engineer made cry woman awesome inspiri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16745</th>\n",
              "      <td>0</td>\n",
              "      <td>maya nope american tired ridicule mythical whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37930</th>\n",
              "      <td>1</td>\n",
              "      <td>madonna advocate day dot fought hard lgbt peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25966</th>\n",
              "      <td>1</td>\n",
              "      <td>peace upon beloved brothers dearest sisters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27917</th>\n",
              "      <td>1</td>\n",
              "      <td>lives matter god</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36087</th>\n",
              "      <td>1</td>\n",
              "      <td>loved kids reactions comments hope next genera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34105</th>\n",
              "      <td>1</td>\n",
              "      <td>taylor school actually every school ever gives...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>33680 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       enc_label                                          cleanText\n",
              "8480           0  think awesome tell like matter color need join...\n",
              "1186           0                                   juan racist guys\n",
              "7818           0  want trump clinton president either nni hate w...\n",
              "24959          1  female engineer made cry woman awesome inspiri...\n",
              "16745          0  maya nope american tired ridicule mythical whi...\n",
              "...          ...                                                ...\n",
              "37930          1  madonna advocate day dot fought hard lgbt peop...\n",
              "25966          1        peace upon beloved brothers dearest sisters\n",
              "27917          1                                   lives matter god\n",
              "36087          1  loved kids reactions comments hope next genera...\n",
              "34105          1  taylor school actually every school ever gives...\n",
              "\n",
              "[33680 rows x 2 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = training_data\n",
        "df = df.drop(['text', 'label'], axis = 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hQD6msbNgKII"
      },
      "outputs": [],
      "source": [
        "X = df.cleanText\n",
        "y = df.enc_label\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4_7UtPOFhM38"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "Xtrain_vects = vectorizer.fit_transform(X_train)\n",
        "Xtest_vects = vectorizer.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "iLyae2_xYoQu"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=48).fit(Xtrain_vects, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIiSgcXGZUSz",
        "outputId": "a47a0373-a8c4-4194-8f35-4816386f649b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on Training Data : 0.9955463182897862\n",
            "Accuracy on Testing Data : 0.9744655581947743\n",
            "The normal f1score : [0.97340754 0.9754426 ] \n",
            "The weighted f1score : 0.9744401803757773 \n",
            "The macro f1score : 0.9744250745311364\n",
            "The microrecall score : 0.9744655581947743 \n",
            "The macrorecall score : 0.9744250745311364 \n",
            "The weightedrecall score : 0.9744655581947743 \n",
            "The normalrecall score : [0.94876432 0.99941486]\n",
            "The micro precision score : 0.9744655581947743 \n",
            "The macro precision score : 0.9759792491080834 \n",
            "The weighted precision score : 0.9756320722931042 \n",
            "The normal precision score : [0.99936508 0.95259342]\n"
          ]
        }
      ],
      "source": [
        "score = clf.score(Xtrain_vects, y_train)\n",
        "score2 = clf.score(Xtest_vects, y_test)\n",
        "print(\"Accuracy on Training Data :\",score)\n",
        "print(\"Accuracy on Testing Data :\",score2)\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "normalscore=f1_score(y_test, clf.predict(Xtest_vects), average = None)\n",
        "weightedscore =f1_score(y_test, clf.predict(Xtest_vects), average = 'weighted')\n",
        "macroscore= f1_score(y_test, clf.predict(Xtest_vects), average = 'macro')\n",
        "microrecall = recall_score(y_test, clf.predict(Xtest_vects), average='micro')\n",
        "macrorecall = recall_score(y_test, clf.predict(Xtest_vects), average='macro')\n",
        "normalrecall = recall_score(y_test, clf.predict(Xtest_vects), average=None)\n",
        "weightedrecall = recall_score(y_test, clf.predict(Xtest_vects), average='weighted')\n",
        "macroprecisionscore= precision_score(y_test, clf.predict(Xtest_vects), average='macro')\n",
        "weightedprecisionscore= precision_score(y_test, clf.predict(Xtest_vects), average='weighted')\n",
        "microprecisionscore= precision_score(y_test, clf.predict(Xtest_vects), average='micro')\n",
        "normalprecisionscore= precision_score(y_test, clf.predict(Xtest_vects), average=None)\n",
        "print('The normal f1score :',normalscore,'\\nThe weighted f1score :',weightedscore,'\\nThe macro f1score :',macroscore)\n",
        "print('The microrecall score :',microrecall,'\\nThe macrorecall score :',macroscore,'\\nThe weightedrecall score :',weightedrecall,'\\nThe normalrecall score :',normalrecall)\n",
        "print('The micro precision score :',microprecisionscore,'\\nThe macro precision score :',macroprecisionscore,'\\nThe weighted precision score :',weightedprecisionscore,'\\nThe normal precision score :',normalprecisionscore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h-2WRbBmZWTT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle_out = open('model.pkl', 'wb')\n",
        "pickle.dump(clf, pickle_out)\n",
        "pickle_out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../NLP-Research-SRM/model.pkl']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(clf,r\"../NLP-Research-SRM/model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hope Speech Detection",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
